#include "audio_capture.h"
#include "esp_log.h"
#include <Arduino.h>
#include <math.h>
#include <string.h>

// æ•¸å­¸å¸¸æ•¸
#ifndef PI
#define PI 3.14159265359f
#endif

static const char *TAG = "AudioCapture";

// å…¨å±€è®Šé‡
int32_t audio_buffer[BUFFER_SIZE];
int16_t processed_audio[BUFFER_SIZE];
float normalized_audio[FRAME_SIZE];
float feature_buffer[FRAME_SIZE];

// éŸ³é »è™•ç†ç‹€æ…‹è®Šé‡
static int16_t frame_buffer[BUFFER_SIZE * 2]; // å¹€ç·©è¡å€ï¼ˆæ”¯æŒé‡ç–Šï¼‰
static size_t frame_write_pos = 0;            // å¯«å…¥ä½ç½®
static bool frame_ready_flag = false;         // å¹€å°±ç·’æ¨™èªŒ

/**
 * åˆå§‹åŒ– I2S ä»‹é¢ç”¨æ–¼ INMP441 éº¥å…‹é¢¨
 */
bool audio_init()
{
    Serial.println("Initializing I2S for INMP441...");

    // I2S é…ç½®çµæ§‹
    i2s_config_t i2s_config = {
        .mode = (i2s_mode_t)(I2S_MODE_MASTER | I2S_MODE_RX), // ä¸»æ¨¡å¼ï¼Œæ¥æ”¶
        .sample_rate = SAMPLE_RATE,
        .bits_per_sample = I2S_BITS_PER_SAMPLE_32BIT,      // 32-bit å®¹å™¨
        .channel_format = I2S_CHANNEL_FMT_ONLY_LEFT,       // åªä½¿ç”¨å·¦è²é“
        .communication_format = I2S_COMM_FORMAT_STAND_I2S, // æ¨™æº– I2S æ ¼å¼
        .intr_alloc_flags = ESP_INTR_FLAG_LEVEL1,          // ä¸­æ–·å„ªå…ˆç´š
        .dma_buf_count = DMA_BUF_COUNT,
        .dma_buf_len = DMA_BUF_LEN,
        .use_apll = false, // ä¸ä½¿ç”¨ APLL
        .tx_desc_auto_clear = false,
        .fixed_mclk = 0};

    // I2S å¼•è…³é…ç½®
    i2s_pin_config_t pin_config = {
        .bck_io_num = I2S_SCK_PIN,         // ä½å…ƒæ™‚é˜å¼•è…³
        .ws_io_num = I2S_WS_PIN,           // å­—é¸å¼•è…³
        .data_out_num = I2S_PIN_NO_CHANGE, // ä¸ä½¿ç”¨è¼¸å‡º
        .data_in_num = I2S_SD_PIN          // æ•¸æ“šè¼¸å…¥å¼•è…³
    };

    // å®‰è£ I2S é©…å‹•
    esp_err_t ret = i2s_driver_install(I2S_PORT, &i2s_config, 0, NULL);
    if (ret != ESP_OK)
    {
        Serial.printf("Failed to install I2S driver: %s\n", esp_err_to_name(ret));
        return false;
    }

    // è¨­ç½® I2S å¼•è…³
    ret = i2s_set_pin(I2S_PORT, &pin_config);
    if (ret != ESP_OK)
    {
        Serial.printf("Failed to set I2S pins: %s\n", esp_err_to_name(ret));
        i2s_driver_uninstall(I2S_PORT);
        return false;
    }

    // æ¸…é™¤ I2S ç·©è¡å€
    ret = i2s_zero_dma_buffer(I2S_PORT);
    if (ret != ESP_OK)
    {
        Serial.printf("Failed to clear I2S buffer: %s\n", esp_err_to_name(ret));
    }

    Serial.println("I2S initialized successfully!");
    return true;
}

/**
 * å¾ INMP441 è®€å–éŸ³é »æ•¸æ“š
 */
size_t audio_read(int32_t *buffer, size_t buffer_size)
{
    size_t bytes_read = 0;

    esp_err_t ret = i2s_read(I2S_PORT, buffer, buffer_size * sizeof(int32_t),
                             &bytes_read, portMAX_DELAY);

    if (ret != ESP_OK)
    {
        Serial.printf("I2S read error: %s\n", esp_err_to_name(ret));
        return 0;
    }

    return bytes_read / sizeof(int32_t); // è¿”å›æ¨£æœ¬æ•¸é‡
}

/**
 * è™•ç†åŸå§‹éŸ³é »æ•¸æ“š
 * å°‡ 32-bit æ•¸æ“šè½‰æ›ç‚º 16-bitï¼Œä¸¦é€²è¡ŒåŸºæœ¬çš„ä¿¡è™Ÿè™•ç†
 */
void audio_process(int32_t *raw_data, int16_t *processed_data, size_t length)
{
    for (size_t i = 0; i < length; i++)
    {
        // INMP441 è¼¸å‡º 24-bit æ•¸æ“šï¼Œä½æ–¼ 32-bit å®¹å™¨çš„é«˜ 24 ä½
        // ä¿®æ­£ï¼šç›´æ¥å³ç§» 8 ä½ä¾†ç²å¾— 24-bit å€¼ï¼Œç„¶å¾Œå†å³ç§» 8 ä½è½‰ç‚º 16-bit
        // ä½†æ˜¯è¦ä¿æŒè¶³å¤ çš„ç²¾åº¦
        int32_t sample = raw_data[i];

        // ç¬¬ä¸€æ­¥ï¼šç²å¾— 24-bit æœ‰ç¬¦è™Ÿå€¼ (å³ç§» 8 ä½)
        sample = sample >> 8;

        // ç¬¬äºŒæ­¥ï¼šè½‰æ›ç‚º 16-bitï¼Œä½†è¦ä¿æŒæ›´å¤šç²¾åº¦ (å³ç§» 4 ä½è€Œä¸æ˜¯ 8 ä½)
        // é€™æ¨£å¯ä»¥ä¿æŒæ›´å¤šçš„éŸ³é »ä¿¡è™Ÿå¼·åº¦
        processed_data[i] = (int16_t)(sample >> 4);

        // èª¿è©¦ï¼šå¢åŠ å¢ç›Šä»¥ç¢ºä¿ä¿¡è™Ÿå¯è¦‹
        processed_data[i] = (int16_t)(processed_data[i] * 4); // 4å€å¢ç›Šç”¨æ–¼èª¿è©¦
    }
}

/**
 * å»åˆå§‹åŒ– I2S
 */
void audio_deinit()
{
    i2s_driver_uninstall(I2S_PORT);
    Serial.println("I2S deinitialized");
}

// ======== éŸ³é »é è™•ç†å‡½æ•¸å¯¦ä½œ ========

/**
 * éŸ³é »æ­£è¦åŒ–ï¼šå°‡ 16-bit æ•´æ•¸è½‰æ›ç‚º [-1.0, 1.0] æµ®é»æ•¸
 */
void audio_normalize(int16_t *input, float *output, size_t length)
{
    for (size_t i = 0; i < length; i++)
    {
        // è½‰æ›ç‚º [-1.0, 1.0] ç¯„åœ
        output[i] = (float)input[i] / MAX_AMPLITUDE * NORMALIZATION_FACTOR;

        // é™åˆ¶ç¯„åœ
        if (output[i] > 1.0f)
            output[i] = 1.0f;
        if (output[i] < -1.0f)
            output[i] = -1.0f;
    }
}

/**
 * æ‡‰ç”¨æ¼¢å¯§çª—å‡½æ•¸ä¾†æ¸›å°‘é »è­œæ´©æ¼
 */
void audio_apply_window(float *data, size_t length)
{
    for (size_t i = 0; i < length; i++)
    {
        float window_val = 0.5f * (1.0f - cos(2.0f * PI * i / (length - 1)));
        data[i] *= window_val;
    }
}

/**
 * è¨ˆç®— RMS (Root Mean Square) èƒ½é‡
 */
float audio_calculate_rms(float *data, size_t length)
{
    float sum = 0.0f;
    for (size_t i = 0; i < length; i++)
    {
        sum += data[i] * data[i];
    }
    return sqrt(sum / length);
}

/**
 * è¨ˆç®—é›¶ç©¿è¶Šç‡ï¼ˆZero Crossing Rateï¼‰
 * ç”¨æ–¼å€åˆ†èªéŸ³å’ŒéŸ³æ¨‚/å™ªè²
 */
float audio_calculate_zero_crossing_rate(int16_t *data, size_t length)
{
    int zero_crossings = 0;
    for (size_t i = 1; i < length; i++)
    {
        if ((data[i] >= 0) != (data[i - 1] >= 0))
        {
            zero_crossings++;
        }
    }
    return (float)zero_crossings / (length - 1);
}

/**
 * æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„éŸ³é »å¹€æº–å‚™å¥½é€²è¡Œè™•ç†
 */
bool audio_frame_ready(int16_t *new_samples, size_t sample_count)
{
    // å°‡æ–°æ¨£æœ¬æ·»åŠ åˆ°å¹€ç·©è¡å€
    for (size_t i = 0; i < sample_count; i++)
    {
        frame_buffer[frame_write_pos] = new_samples[i];
        frame_write_pos++;

        // æª¢æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„å¹€
        if (frame_write_pos >= FRAME_SIZE)
        {
            frame_ready_flag = true;

            // ç§»å‹•æ•¸æ“šä»¥æ”¯æŒé‡ç–Šè™•ç†
            // å°‡å¾ŒåŠéƒ¨åˆ†ç§»åˆ°å‰åŠéƒ¨åˆ†
            memmove(frame_buffer, frame_buffer + FRAME_SIZE - FRAME_OVERLAP,
                    FRAME_OVERLAP * sizeof(int16_t));
            frame_write_pos = FRAME_OVERLAP;

            return true;
        }
    }

    return false;
}

/**
 * ç²å–ç•¶å‰éŸ³é »å¹€ï¼ˆæ­£è¦åŒ–ä¸¦æ‡‰ç”¨çª—å‡½æ•¸ï¼‰
 */
void audio_get_current_frame(float *frame_output)
{
    if (!frame_ready_flag)
        return;

    // å¾ç·©è¡å€è¤‡è£½ä¸€å€‹å®Œæ•´å¹€
    int16_t temp_frame[FRAME_SIZE];
    memcpy(temp_frame, frame_buffer, FRAME_SIZE * sizeof(int16_t));

    // æ­£è¦åŒ–
    audio_normalize(temp_frame, frame_output, FRAME_SIZE);

    // æ‡‰ç”¨çª—å‡½æ•¸
    audio_apply_window(frame_output, FRAME_SIZE);

    frame_ready_flag = false;
}

/**
 * æå–éŸ³é »ç‰¹å¾µ
 */
void audio_extract_features(float *frame, AudioFeatures *features)
{
    // è¨ˆç®— RMS èƒ½é‡
    features->rms_energy = audio_calculate_rms(frame, FRAME_SIZE);

    // ç‚ºäº†è¨ˆç®—é›¶ç©¿è¶Šç‡ï¼Œæˆ‘å€‘éœ€è¦å°‡æµ®é»æ•¸è½‰å›æ•´æ•¸
    int16_t temp_samples[FRAME_SIZE];
    for (size_t i = 0; i < FRAME_SIZE; i++)
    {
        temp_samples[i] = (int16_t)(frame[i] * MAX_AMPLITUDE);
    }

    // è¨ˆç®—é›¶ç©¿è¶Šç‡
    features->zero_crossing_rate = audio_calculate_zero_crossing_rate(temp_samples, FRAME_SIZE);

    // ç°¡åŒ–çš„é »è­œé‡å¿ƒè¨ˆç®—ï¼ˆåŸºæ–¼é«˜é »å…§å®¹ï¼‰
    float high_freq_energy = 0.0f;
    float total_energy = 0.0f;

    for (size_t i = 0; i < FRAME_SIZE; i++)
    {
        float energy = frame[i] * frame[i];
        total_energy += energy;

        // ç°¡å–®åœ°å°‡å¾ŒåŠéƒ¨åˆ†è¦–ç‚ºé«˜é »
        if (i > FRAME_SIZE / 2)
        {
            high_freq_energy += energy;
        }
    }

    features->spectral_centroid = (total_energy > 0) ? (high_freq_energy / total_energy) : 0.0f;

    // èª¿è©¦ï¼šç¢ºä¿ç‰¹å¾µå€¼ä¸æœƒå¤ªå°è¢«å¿½ç•¥
    if (features->rms_energy < 0.001f && total_energy > 0.0f)
    {
        features->rms_energy = sqrtf(total_energy / FRAME_SIZE);
    }

    // èªéŸ³æª¢æ¸¬é‚è¼¯ (æ”¾å¯¬æ¢ä»¶)
    // èªéŸ³é€šå¸¸æœ‰ï¼šé©ä¸­çš„èƒ½é‡ã€é©ä¸­çš„é›¶ç©¿è¶Šç‡ã€å¹³è¡¡çš„é »è­œ
    features->is_voice_detected =
        (features->rms_energy > 0.001f && features->rms_energy < 0.8f) &&                // é™ä½æœ€å°èƒ½é‡é–¾å€¼
        (features->zero_crossing_rate > 0.01f && features->zero_crossing_rate < 0.5f) && // æ”¾å¯¬é›¶ç©¿è¶Šç‡ç¯„åœ
        (features->spectral_centroid > 0.05f && features->spectral_centroid < 0.95f);    // æ”¾å¯¬é »è­œç¯„åœ
}

// ========== èªéŸ³æ´»å‹•æª¢æ¸¬ (VAD) ç³»çµ± ==========

// VAD ç‹€æ…‹è®Šé‡
static VADState vad_current_state = VAD_SILENCE;
static int speech_frame_count = 0;      // é€£çºŒèªéŸ³å¹€è¨ˆæ•¸
static int silence_frame_count = 0;     // é€£çºŒéœéŸ³å¹€è¨ˆæ•¸
static unsigned long speech_start_time = 0;
static unsigned long speech_end_time = 0;

// èªéŸ³ç·©è¡ç³»çµ±
float speech_buffer[SPEECH_BUFFER_SIZE];
int speech_buffer_length = 0;

/**
 * èªéŸ³æ´»å‹•æª¢æ¸¬ä¸»è™•ç†å‡½æ•¸
 */
VADResult audio_vad_process(const AudioFeatures *features)
{
    VADResult result;
    result.state = vad_current_state;
    result.speech_detected = false;
    result.speech_complete = false;
    result.energy_level = features->rms_energy;
    result.duration_ms = 0;

    unsigned long current_time = millis();
    bool is_speech_energy = (features->rms_energy > VAD_ENERGY_THRESHOLD);
    
    switch (vad_current_state)
    {
    case VAD_SILENCE:
        if (is_speech_energy && features->is_voice_detected)
        {
            speech_frame_count++;
            silence_frame_count = 0;
            
            if (speech_frame_count >= VAD_START_FRAMES)
            {
                // èªéŸ³é–‹å§‹
                vad_current_state = VAD_SPEECH_START;
                speech_start_time = current_time;
                speech_buffer_length = 0;  // æ¸…ç©ºèªéŸ³ç·©è¡
                result.state = VAD_SPEECH_START;
                result.speech_detected = true;
                
                Serial.println("ğŸ¤ èªéŸ³é–‹å§‹æª¢æ¸¬");
            }
        }
        else
        {
            speech_frame_count = 0;
        }
        break;

    case VAD_SPEECH_START:
        vad_current_state = VAD_SPEECH_ACTIVE;
        result.state = VAD_SPEECH_ACTIVE;
        // ç¹¼çºŒåˆ° SPEECH_ACTIVE è™•ç†
        
    case VAD_SPEECH_ACTIVE:
        if (is_speech_energy || features->is_voice_detected)
        {
            silence_frame_count = 0;
            result.speech_detected = true;
        }
        else
        {
            silence_frame_count++;
            
            if (silence_frame_count >= VAD_END_FRAMES)
            {
                // èªéŸ³çµæŸ
                speech_end_time = current_time;
                unsigned long duration = speech_end_time - speech_start_time;
                
                if (duration >= VAD_MIN_SPEECH_DURATION)
                {
                    // æœ‰æ•ˆçš„èªéŸ³æ®µè½
                    vad_current_state = VAD_SPEECH_END;
                    result.state = VAD_SPEECH_END;
                    result.speech_complete = true;
                    result.duration_ms = duration;
                    
                    Serial.printf("âœ… èªéŸ³çµæŸ - æŒçºŒæ™‚é–“: %lu ms\n", duration);
                }
                else
                {
                    // å¤ªçŸ­ï¼Œå›åˆ°éœéŸ³ç‹€æ…‹
                    Serial.printf("âš ï¸  èªéŸ³å¤ªçŸ­ (%lu ms)ï¼Œå¿½ç•¥\n", duration);
                    audio_vad_reset();
                }
            }
        }
        
        // è¶…æ™‚ä¿è­·
        if ((current_time - speech_start_time) > VAD_MAX_SPEECH_DURATION)
        {
            Serial.println("â° èªéŸ³è¶…æ™‚ï¼Œå¼·åˆ¶çµæŸ");
            vad_current_state = VAD_SPEECH_END;
            result.state = VAD_SPEECH_END;
            result.speech_complete = true;
            result.duration_ms = current_time - speech_start_time;
        }
        break;

    case VAD_SPEECH_END:
        // è™•ç†å®Œæ•´èªéŸ³å¾Œé‡ç½®åˆ°éœéŸ³ç‹€æ…‹
        audio_vad_reset();
        result.state = VAD_SILENCE;
        break;
    }

    return result;
}

/**
 * é‡ç½® VAD ç‹€æ…‹
 */
void audio_vad_reset()
{
    vad_current_state = VAD_SILENCE;
    speech_frame_count = 0;
    silence_frame_count = 0;
    speech_start_time = 0;
    speech_end_time = 0;
}

/**
 * æ”¶é›†èªéŸ³æ®µè½åˆ°ç·©è¡å€ï¼ˆæ™ºèƒ½ç®¡ç†ï¼‰
 */
bool audio_collect_speech_segment(const float *frame, size_t frame_size)
{
    // æª¢æŸ¥ç·©è¡å€æ˜¯å¦æœ‰è¶³å¤ ç©ºé–“
    if (speech_buffer_length + frame_size > SPEECH_BUFFER_SIZE)
    {
        // ç·©è¡å€æ»¿æ™‚çš„ç­–ç•¥ï¼šä¿ç•™æœ€å¾Œ75%çš„æ•¸æ“šï¼Œä¸Ÿæ£„å‰é¢25%
        int keep_samples = SPEECH_BUFFER_SIZE * 3 / 4;  // ä¿ç•™75%
        int discard_samples = SPEECH_BUFFER_SIZE - keep_samples;
        
        // å°‡å¾Œé¢çš„æ•¸æ“šç§»åˆ°å‰é¢
        memmove(speech_buffer, &speech_buffer[discard_samples], keep_samples * sizeof(float));
        speech_buffer_length = keep_samples;
        
        // éœé»˜è™•ç†ï¼Œæ¸›å°‘è­¦å‘Šé »ç‡
        static unsigned long last_warning = 0;
        unsigned long now = millis();
        if (now - last_warning > 2000) {
            Serial.printf("ğŸ”„ ç·©è¡å€å¾ªç’°ä½¿ç”¨ - ä¿ç•™æœ€æ–° %.1f ç§’èªéŸ³\n", (float)keep_samples / SAMPLE_RATE);
            last_warning = now;
        }
    }
    
    // å°‡éŸ³é »å¹€è¤‡è£½åˆ°èªéŸ³ç·©è¡å€
    memcpy(&speech_buffer[speech_buffer_length], frame, frame_size * sizeof(float));
    speech_buffer_length += frame_size;
    
    return true;
}

/**
 * è™•ç†å®Œæ•´çš„èªéŸ³æ®µè½
 */
void audio_process_complete_speech()
{
    if (speech_buffer_length == 0)
    {
        Serial.println("âŒ æ²’æœ‰èªéŸ³æ•¸æ“šå¯è™•ç†");
        return;
    }
    
    Serial.printf("ğŸ”„ è™•ç†å®Œæ•´èªéŸ³æ®µè½ - é•·åº¦: %d æ¨£æœ¬\n", speech_buffer_length);
    
    // é€™è£¡æœƒåœ¨å¾Œé¢èˆ‡é—œéµå­—æª¢æ¸¬æ•´åˆ
    // ç¾åœ¨å…ˆé‡ç½®ç·©è¡å€
    speech_buffer_length = 0;
}