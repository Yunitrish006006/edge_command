#include "voice_model.h"
#include <math.h>
#include <string.h>

// ç°¡å–®çš„çµ•å°å€¼å‡½æ•¸ï¼Œé¿å…å‘½åè¡çª
float abs_f(float x)
{
    return (x >= 0) ? x : -x;
}

// å…¨å±€æ¨¡å‹å¯¦ä¾‹
VoiceModel voice_model;

VoiceModel::VoiceModel()
{
    reset();
}

void VoiceModel::reset()
{
    // æ¸…ç©ºæ­·å²è¨˜éŒ„
    memset(history, 0, sizeof(history));
    memset(confidence_history, 0, sizeof(confidence_history));
    history_index = 0;
    frame_count = 0;

    // é‡ç½®çµ±è¨ˆè³‡è¨Š
    running_energy_avg = 0.0f;
    running_zcr_avg = 0.0f;
    total_frames = 0;
}

VoiceModelResult VoiceModel::inference(const AudioFeatures &features)
{
    VoiceModelResult result;

    // è¨ˆç®—å„é …è©•åˆ†
    result.energy_score = calculate_energy_score(features.rms_energy);
    result.spectral_score = calculate_spectral_score(features.zero_crossing_rate, features.spectral_centroid);
    result.temporal_score = calculate_temporal_score(features.rms_energy, features.zero_crossing_rate);

    // é€²è¡Œåˆ†é¡
    result.classification = classify_features(result.energy_score, result.spectral_score, result.temporal_score);

    // è¨ˆç®—ç½®ä¿¡åº¦
    result.confidence = calculate_confidence(features, result.classification);

    // è¨ˆç®—èªéŸ³æ©Ÿç‡å’Œæ´»å‹•æ°´æº–
    result.voice_probability = (result.classification == VOICE_SPEECH) ? result.confidence : (1.0f - result.confidence);
    result.activity_level = result.energy_score;

    // æ›´æ–°æ­·å²å’Œçµ±è¨ˆ
    add_to_history(result.classification, result.confidence);
    update_running_stats(features);

    frame_count++;

    return result;
}

float VoiceModel::calculate_energy_score(float energy)
{
    // å°‡èƒ½é‡æ˜ å°„åˆ° 0-1 åˆ†æ•¸
    if (energy <= SILENCE_ENERGY_THRESHOLD)
    {
        return 0.0f;
    }
    else if (energy >= 1.0f)
    {
        return 1.0f;
    }
    else
    {
        // å°æ•¸ç¸®æ”¾ä»¥æ›´å¥½åœ°è™•ç†å‹•æ…‹ç¯„åœ
        return log10(energy * 10.0f + 1.0f) / log10(11.0f);
    }
}

float VoiceModel::calculate_spectral_score(float zcr, float spectral_centroid)
{
    // åŸºæ–¼é›¶ç©¿è¶Šç‡å’Œé »è­œé‡å¿ƒè¨ˆç®—é »è­œè©•åˆ†
    float zcr_score = 0.0f;
    float centroid_score = 0.0f;

    // èªéŸ³çš„ ZCR é€šå¸¸åœ¨ä¸­ç­‰ç¯„åœ
    if (zcr >= SPEECH_ZCR_MIN && zcr <= SPEECH_ZCR_MAX)
    {
        zcr_score = 1.0f - abs_f(zcr - (SPEECH_ZCR_MIN + SPEECH_ZCR_MAX) / 2.0f) / ((SPEECH_ZCR_MAX - SPEECH_ZCR_MIN) / 2.0f);
    }
    else if (zcr > NOISE_ZCR_MIN)
    {
        zcr_score = 0.2f; // å¯èƒ½æ˜¯å™ªéŸ³
    }

    // èªéŸ³çš„é »è­œé‡å¿ƒé€šå¸¸å¹³è¡¡
    if (spectral_centroid >= 0.2f && spectral_centroid <= 0.8f)
    {
        centroid_score = 1.0f - abs_f(spectral_centroid - 0.5f) * 2.0f;
    }

    return (zcr_score + centroid_score) / 2.0f;
}

float VoiceModel::calculate_temporal_score(float energy, float zcr)
{
    // åŸºæ–¼æ™‚åŸŸç‰¹æ€§è¨ˆç®—è©•åˆ†
    float consistency_score = 1.0f;

    // æª¢æŸ¥èˆ‡æ­·å²å¹³å‡çš„ä¸€è‡´æ€§
    if (total_frames > 5)
    {
        float energy_deviation = abs_f(energy - running_energy_avg) / (running_energy_avg + 0.001f);
        float zcr_deviation = abs_f(zcr - running_zcr_avg) / (running_zcr_avg + 0.001f);

        // èªéŸ³é€šå¸¸æœ‰é©åº¦çš„è®ŠåŒ–
        if (energy_deviation < 2.0f && zcr_deviation < 1.0f)
        {
            consistency_score = 1.0f;
        }
        else
        {
            consistency_score = max(0.3f, 1.0f - (energy_deviation + zcr_deviation) / 4.0f);
        }
    }

    return consistency_score;
}

VoiceModelOutput VoiceModel::classify_features(float energy_score, float spectral_score, float temporal_score)
{
    // ç¶œåˆè©•åˆ†
    float overall_score = (energy_score + spectral_score + temporal_score) / 3.0f;

    // éœéŸ³æª¢æ¸¬ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰
    if (energy_score < 0.1f)
    {
        return VOICE_SILENCE;
    }

    // èªéŸ³æª¢æ¸¬
    if (overall_score > 0.6f && spectral_score > 0.5f && energy_score > 0.2f)
    {
        return VOICE_SPEECH;
    }

    // éŸ³æ¨‚æª¢æ¸¬ï¼ˆä½ZCRï¼Œé«˜èƒ½é‡ï¼‰
    if (energy_score > 0.3f && spectral_score < 0.3f)
    {
        return VOICE_MUSIC;
    }

    // èƒŒæ™¯å™ªéŸ³ï¼ˆä¸­ç­‰èƒ½é‡ï¼Œå„ç¨®é »è­œç‰¹æ€§ï¼‰
    if (energy_score > 0.1f && energy_score < 0.5f)
    {
        return VOICE_BACKGROUND;
    }

    return VOICE_UNKNOWN;
}

float VoiceModel::calculate_confidence(const AudioFeatures &features, VoiceModelOutput classification)
{
    float confidence = 0.5f; // åŸºæº–ç½®ä¿¡åº¦

    switch (classification)
    {
    case VOICE_SILENCE:
        confidence = 1.0f - features.rms_energy * 10.0f; // èƒ½é‡è¶Šä½ï¼ŒéœéŸ³ç½®ä¿¡åº¦è¶Šé«˜
        break;

    case VOICE_SPEECH:
        // èªéŸ³ç½®ä¿¡åº¦åŸºæ–¼ç‰¹å¾µçš„å…¸å‹æ€§
        if (features.rms_energy >= SPEECH_ENERGY_MIN && features.rms_energy <= SPEECH_ENERGY_MAX &&
            features.zero_crossing_rate >= SPEECH_ZCR_MIN && features.zero_crossing_rate <= SPEECH_ZCR_MAX)
        {
            confidence = 0.8f + min(0.2f, features.rms_energy * 2.0f);
        }
        else
        {
            confidence = 0.6f;
        }
        break;

    case VOICE_MUSIC:
        confidence = 0.7f + min(0.3f, features.rms_energy);
        break;

    case VOICE_BACKGROUND:
        confidence = 0.6f + min(0.2f, features.rms_energy);
        break;

    default:
        confidence = 0.4f;
        break;
    }

    return max(0.0f, min(1.0f, confidence));
}

void VoiceModel::update_running_stats(const AudioFeatures &features)
{
    float alpha = 0.1f; // å¹³æ»‘ä¿‚æ•¸

    if (total_frames == 0)
    {
        running_energy_avg = features.rms_energy;
        running_zcr_avg = features.zero_crossing_rate;
    }
    else
    {
        running_energy_avg = running_energy_avg * (1.0f - alpha) + features.rms_energy * alpha;
        running_zcr_avg = running_zcr_avg * (1.0f - alpha) + features.zero_crossing_rate * alpha;
    }

    total_frames++;
}

void VoiceModel::add_to_history(VoiceModelOutput classification, float confidence)
{
    history[history_index] = classification;
    confidence_history[history_index] = confidence;
    history_index = (history_index + 1) % HISTORY_SIZE;
}

VoiceModelOutput VoiceModel::get_smoothed_classification()
{
    // çµ±è¨ˆæœ€è¿‘çš„åˆ†é¡çµæœ
    int counts[5] = {0}; // å°æ‡‰ 5 å€‹é¡åˆ¥

    int frames_to_check = min(frame_count, HISTORY_SIZE);
    for (int i = 0; i < frames_to_check; i++)
    {
        int idx = (history_index - 1 - i + HISTORY_SIZE) % HISTORY_SIZE;
        counts[history[idx]]++;
    }

    // æ‰¾å‡ºæœ€å¸¸è¦‹çš„åˆ†é¡
    VoiceModelOutput most_common = VOICE_UNKNOWN;
    int max_count = 0;

    for (int i = 0; i < 5; i++)
    {
        if (counts[i] > max_count)
        {
            max_count = counts[i];
            most_common = (VoiceModelOutput)i;
        }
    }

    return most_common;
}

float VoiceModel::get_average_confidence()
{
    if (frame_count == 0)
        return 0.0f;

    float sum = 0.0f;
    int frames_to_check = min(frame_count, HISTORY_SIZE);

    for (int i = 0; i < frames_to_check; i++)
    {
        int idx = (history_index - 1 - i + HISTORY_SIZE) % HISTORY_SIZE;
        sum += confidence_history[idx];
    }

    return sum / frames_to_check;
}

void VoiceModel::print_model_stats()
{
    Serial.println("\nğŸ“ˆ === VOICE MODEL STATISTICS ===");
    Serial.printf("Total frames processed: %d\n", total_frames);
    Serial.printf("Running energy average: %.4f\n", running_energy_avg);
    Serial.printf("Running ZCR average: %.4f\n", running_zcr_avg);

    VoiceModelOutput smoothed = get_smoothed_classification();
    float avg_confidence = get_average_confidence();

    Serial.printf("Smoothed classification: %s (%.2f confidence)\n",
                  voice_output_to_string(smoothed), avg_confidence);
    Serial.println("===============================\n");
}

// ä¾¿åˆ©å‡½æ•¸å¯¦ç¾
const char *voice_output_to_string(VoiceModelOutput output)
{
    switch (output)
    {
    case VOICE_SILENCE:
        return "Silence";
    case VOICE_BACKGROUND:
        return "Background";
    case VOICE_SPEECH:
        return "Speech";
    case VOICE_MUSIC:
        return "Music";
    case VOICE_UNKNOWN:
        return "Unknown";
    default:
        return "Invalid";
    }
}

const char *get_voice_emoji(VoiceModelOutput output)
{
    switch (output)
    {
    case VOICE_SILENCE:
        return "ğŸ”‡";
    case VOICE_BACKGROUND:
        return "ğŸŒ«ï¸";
    case VOICE_SPEECH:
        return "ğŸ—£ï¸";
    case VOICE_MUSIC:
        return "ğŸµ";
    case VOICE_UNKNOWN:
        return "â“";
    default:
        return "âš ï¸";
    }
}